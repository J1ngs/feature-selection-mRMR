% feature-selection-mRMR
% Created by Jiahong K. Chen

% Input: 
%       dataX n-by-p, n is #observation, p is dim of feature
%       dataC n-by-1, the class of observations
%       nMRMR       , dimension of feature subspace generated by mRMR
%       classifier  , 'NB' or 'LDA'
% Output: candidate feature set

function candiFea = candidateFeature(dataX, dataC, nMRMR, classifier, errThres)

mrmrFea = mRMR(dataX, dataC, nMRMR);

% nSample = size(dataX, 1);
kFold   = 10;

meanErr = zeros(nMRMR, 1);
varErr  = zeros(nMRMR, 1);
mt2Err  = zeros(nMRMR, 1);

for Sid = 1 : nMRMR

    feaIdx = mrmrFea(1:Sid);
    [meanErr(Sid) ,varErr(Sid), mt2Err(Sid)] = ...
        cvErrEst(dataX(:,feaIdx), dataC, classifier, kFold);

end

goodIdx = find(mt2Err < errThres);

[~, greatIdx ] = min( meanErr(goodIdx) );

candiFea = mrmrFea( 1 : goodIdx(greatIdx) );

end

function [meanErr, varErr, mt2Err] = cvErrEst(dataX, dataC, classifier, kFold)

% not support for R2011a
% if strcmp(classifier,'LDA')
%     classifyFun = @fitcdiscr;
% elseif strcmp(classifier,'NB')
%     classifyFun = @NaiveBayes.fit;
% else
%     error('Incorrect classifier')
% end

nSample = size(dataX, 1);
indices = crossvalind('Kfold', nSample, kFold);

errSn   = zeros(kFold, 1);

for i = 1:kFold
    
    cp          = classperf(dataC);
    test        = (indices == i); 
    train       = ~test;
    
    if strcmp(classifier,'LDA')
        predClass   = classify(dataX(test,:), dataX(train,:), dataC(train,:));
    elseif strcmp(classifier,'NB')
        fitModel    = NaiveBayes.fit(dataX(train,:), dataC(train,:), 'Distribution', 'mn');
        predClass   = predict(fitModel, dataX(test,:));
    else
        error('Incorrect classifier')
    end

    classperf(cp, predClass, test);
    
    errSn(i)    = cp.ErrorRate;

end

meanErr = mean(errSn);
varErr  = var(errSn);
mt2Err  = mean(errSn.^2);

end

