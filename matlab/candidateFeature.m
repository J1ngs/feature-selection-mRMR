% Input: 
%       dataX n-by-p, n is #observation, p is dim of feature
%       dataC n-by-1, the class of observations
%       nMRMR       , dimension of feature subspace generated by mRMR
%       wrapper     , 'back' or 'for'
%       classifier  , 'NB' or 'LDA'
% Output: candidate feature set

function candiFea = candidateFeature(dataX, dataC, nMRMR, wrapper, classifier)

% mrmrFea = mRMR(dataX, dataC, nMRMR);

nSample = size(dataX, 1);
kFold   = 10;

[meanErr, varErr] = cvErrEst(dataX, dataC, classifier, kFold)

candiFea = [meanErr, varErr];

end

function [meanErr, varErr] = cvErrEst(dataX, dataC, classifier, kFold)

% not support for R2011a
% if strcmp(classifier,'LDA')
%     classifyFun = @fitcdiscr;
% elseif strcmp(classifier,'NB')
%     classifyFun = @NaiveBayes.fit;
% else
%     error('Incorrect classifier')
% end

nSample = size(dataX, 1);
indices = crossvalind('Kfold', nSample, kFold);

errSn   = zeros(kFold, 1);

for i = 1:kFold
    
    cp          = classperf(dataC);
    test        = (indices == i); 
    train       = ~test;
    
    if strcmp(classifier,'LDA')
        predClass   = classify(dataX(test,:), dataX(train,:), dataC(train,:));
    elseif strcmp(classifier,'NB')
        fitModel    = NaiveBayes.fit(dataX(train,:), dataC(train,:));
        predClass   = predict(fitModel, dataX(test,:));
    else
        error('Incorrect classifier')
    end

    classperf(cp, predClass, test);
    
    errSn(i)    = cp.ErrorRate;

end

meanErr = mean(errSn);
varErr  = var(errSn);

end

