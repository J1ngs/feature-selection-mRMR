% Input: 
%       dataX n-by-p, n is #observation, p is dim of feature
%       dataC n-by-1, the class of observations
%       nMRMR       , dimension of feature subspace generated by mRMR
%       wrapper     , 'back' or 'for'
%       classifier  , 'NB' or 'LDA'
% Output: candidate feature set

function candiFea = candidateFeature(dataX, dataC, nMRMR, wrapper, classifier)

mrmrFea = mRMR(dataX, dataC, nMRMR);

if classifier == 'LDA'
    classifyFun = @fitcdiscr;
elseif classifier == 'NB'
    classifyFun = @fitNaiveBayes;
else
    error('Incorrect classifier')
end

nSample = size(dataX, 1);
KFold   = 10;

indices = crossvalind('Kfold', nSample, kFold);

for i = 1:10
    cp          = [];
    testIdx     = (indices == i); 
    trainIdx    = ~test;
    fitModel    = classifyFun(dataX(t))
    classperf(cp,class,test)
end
cp.ErrorRate

ans =

    0.0200

end